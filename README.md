Approach ‚Äì Round 1B: Persona-Based Intelligence Extractor
The core objective of this round is to go beyond generic PDF parsing and extract persona-specific insights from any PDF document. Given a user persona and their job-to-be-done, our system scans the document and outputs only the most relevant sections, ranked by importance. The focus is on offline execution, speed, and flexibility ‚Äî without using any heavy ML models or internet services.

We use PyMuPDF (fitz) to parse the PDF and keyword-matching logic to filter sections based on the persona‚Äôs needs. Additionally, langdetect is used for multilingual support, ensuring non-English content is appropriately identified.

‚öô Step-by-Step Process
1Ô∏è‚É£ Reading the Persona
The script starts by reading persona.json, which contains:

A persona (e.g., ‚ÄúInvestment Analyst‚Äù)

A job_to_be_done (e.g., ‚ÄúAnalyze revenue trends, R&D investments...‚Äù)

This defines the intent and guides the ranking logic.

2Ô∏è‚É£ Reading the PDF
All .pdf files inside the /input folder are processed.

Using PyMuPDF, we iterate through each page of each document.

The page content is extracted using page.get_text("dict"), giving access to individual spans (blocks of text).

3Ô∏è‚É£ Language Detection (Multilingual Support)
Using langdetect, we test each block of text to detect if it‚Äôs in English or another language.

This allows us to:

Include non-English content in the future

Warn or skip unsupported languages

Prepare for multilingual extensions in Round 2

4Ô∏è‚É£ Section Filtering & Relevance Scoring
Text blocks are split into lines.

Each line is checked for keywords from the job_to_be_done.

A basic scoring system ranks sections by counting how many keywords are matched.

High-scoring sections are assumed to be important and are selected for the output.

Example keywords for an investment analyst might include:

revenue, income, R&D, growth, strategy, market, competitor, innovation

5Ô∏è‚É£ Output Structuring
Each relevant section is saved in the output JSON with:

üìÑ Document name

üìÑ Page number (1-indexed)

üìå Extracted section text

‚≠ê Importance rank (higher score = higher rank)

Example:

json
Copy
Edit
{
  "document": "annual_report.pdf",
  "page_number": 5,
  "section_title": "The TPS review of UI Revenue Operations completed April 30",
  "importance_rank": 1
}
This output is saved in /output/persona_output.json.

6Ô∏è‚É£ Automation Across Files
All .pdf files in the /input folder are processed in a loop.

The script can handle multiple PDFs and append results.

Fully compatible with Adobe's expected Docker directory structure.

‚ö° Performance & Efficiency
Entire pipeline runs in under 10 seconds for medium-sized PDFs (up to 50 pages).

No internet access required ‚úÖ

No GPU or external dependencies ‚úÖ

Lightweight: runs in Docker or native Python with minimal setup ‚úÖ
